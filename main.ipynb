{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import jieba.posseg as posseg\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "###################################################\n",
    "# TextRank实现\n",
    "###################################################\n",
    "\n",
    "\n",
    "# 停用词路径\n",
    "stopwords_path = 'stopwords.txt'\n",
    "# 需要排除的词性\n",
    "stopPOS = []\n",
    "\n",
    "# 读取停用词\n",
    "with open(stopwords_path, 'r', encoding='utf-8') as f:\n",
    "    stopwords = [line.strip() for line in f.readlines()]\n",
    "\n",
    "def segment_text_to_sentence(text):\n",
    "    # 将文本分割成句子\n",
    "    sentences = re.split(r'[。！？!?]', text)\n",
    "    sentences = [sentence.strip().replace(\" \", \"\").replace('\\n','') for sentence in sentences if sentence.strip()]\n",
    "    return sentences\n",
    "\n",
    "def segment_text_to_words(text, use_stopwords):\n",
    "    # 分词并去除停用词\n",
    "    global stopPOS, stopwords\n",
    "    stopPOS = [item.lower() for item in stopPOS]\n",
    "    words = posseg.cut(text)\n",
    "    if use_stopwords:\n",
    "        words = [word for word, flag in words if flag[0].lower() not in stopPOS and word not in stopwords]\n",
    "    else:\n",
    "        words = [word for word, flag in words if flag[0].lower() not in stopPOS]\n",
    "    words = set(words)\n",
    "\n",
    "    return words\n",
    "\n",
    "def original_similarity_matrix(sentences, use_stopwords):\n",
    "    # 计算原始相似性矩阵\n",
    "    sentence_words = [set(segment_text_to_words(item, use_stopwords)) for item in sentences]\n",
    "    size = len(sentences)\n",
    "    similarity_matrix = np.zeros((size, size))\n",
    "    for i in range(size):\n",
    "        for j in range(i+1, size):\n",
    "            if len(sentence_words[i]) == 0 or len(sentence_words[j]) == 0:\n",
    "                similarity = 0\n",
    "            else:\n",
    "                # 计算相似性\n",
    "                similarity = len(sentence_words[i] & sentence_words[j]) / (np.log(len(sentence_words[i])) + np.log(len(sentence_words[i])) + 1e-10)\n",
    "            similarity_matrix[i][j] = similarity_matrix[j][i] = similarity\n",
    "    return similarity_matrix\n",
    "\n",
    "def cosine_tfidf_similarity_matrix(sentences, use_stopwords):\n",
    "    # 计算基于TF-IDF的余弦相似性矩阵\n",
    "    sentence_words = [' '.join(segment_text_to_words(item, use_stopwords)) for item in sentences]\n",
    "    tfidf_vectorizer = TfidfVectorizer()\n",
    "    tfidf_matrix = tfidf_vectorizer.fit_transform(sentence_words)\n",
    "    similarity_matrix = cosine_similarity(tfidf_matrix)\n",
    "    \n",
    "    # 将对角线元素设置为0，避免自身与自身的相似性干扰\n",
    "    np.fill_diagonal(similarity_matrix, 0)\n",
    "    return similarity_matrix\n",
    "\n",
    "def summarize_text_rank(text, d=0.85, iter_num=200, top=3, method='默认方式', use_stopwords=True):\n",
    "    sentences = segment_text_to_sentence(text)\n",
    "\n",
    "    print('---------开始----------------------------------------')\n",
    "    if method == '默认方式':\n",
    "        edge_weight = original_similarity_matrix(sentences, use_stopwords)\n",
    "    elif method == 'TF-IDF':\n",
    "        edge_weight = cosine_tfidf_similarity_matrix(sentences, use_stopwords)\n",
    "        \n",
    "    node_weight = np.ones((len(sentences)))\n",
    "\n",
    "    for num in range(iter_num):                \n",
    "        # TextRank迭代公式\n",
    "        node_weight_new = (1-d) + d * node_weight @ (edge_weight / (edge_weight.sum(axis=-1) + 1e-10)).T\n",
    "        if ((node_weight_new - node_weight)**2).sum() < 1e-10:\n",
    "            break\n",
    "        node_weight = node_weight_new\n",
    "\n",
    "    if num < iter_num:\n",
    "        print('迭代{}次，收敛'.format(num))\n",
    "    else:\n",
    "        print('迭代{}次，未收敛'.format(num))\n",
    "\n",
    "    sorted_indices = np.argsort(node_weight)[::-1]\n",
    "\n",
    "    # 获取最大的几个值及其对应的索引\n",
    "    top_indices = sorted(sorted_indices[:top])\n",
    "    top_values = node_weight[top_indices]\n",
    "\n",
    "    print('最大的{}个值：'.format(top), top_values)\n",
    "    print('对应的索引：', top_indices)\n",
    "    print('结果：')\n",
    "    result = ''\n",
    "    for idx in top_indices:\n",
    "        result += sentences[idx] + '。\\n'\n",
    "    print(result)\n",
    "\n",
    "    return result\n",
    "\n",
    "# 示例\n",
    "# text = '在这里输入你的文本'\n",
    "# summarize_text_rank(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "###################################################\n",
    "# MT5实现\n",
    "###################################################\n",
    "\n",
    "flag = True\n",
    "\n",
    "# 尝试导入必要的库和模型\n",
    "try:\n",
    "    import re\n",
    "    from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "\n",
    "    # 定义用于处理空格和换行符的函数\n",
    "    WHITESPACE_HANDLER = lambda k: re.sub('\\s+', ' ', re.sub('\\n+', ' ', k.strip()))\n",
    "\n",
    "    # 定义MT5模型的名称\n",
    "    model_name = \"./mt5-base\"\n",
    "    \n",
    "    # 使用AutoTokenizer加载预训练的MT5分词器\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "    \n",
    "    # 使用AutoModelForSeq2SeqLM加载预训练的MT5模型\n",
    "    model = AutoModelForSeq2SeqLM.from_pretrained(model_name)\n",
    "except:\n",
    "    # 如果导入失败，将flag设置为False\n",
    "    flag = False\n",
    "\n",
    "def summary_mt5(text):\n",
    "    global flag\n",
    "    # 检查MT5模型是否成功导入\n",
    "    if not flag:\n",
    "        return 'MT5模型未导入'\n",
    "    \n",
    "    try:\n",
    "        # 使用MT5分词器对输入文本进行处理，并生成输入的token ID\n",
    "        input_ids = tokenizer(\n",
    "            [WHITESPACE_HANDLER(text)],\n",
    "            return_tensors=\"pt\",\n",
    "            padding=\"max_length\",\n",
    "            truncation=True,\n",
    "            max_length=512\n",
    "        )[\"input_ids\"]\n",
    "\n",
    "        # 使用MT5模型生成摘要\n",
    "        output_ids = model.generate(\n",
    "            input_ids=input_ids,\n",
    "            max_length=84,\n",
    "            no_repeat_ngram_size=2,\n",
    "            num_beams=4\n",
    "        )[0]\n",
    "\n",
    "        # 解码生成的token ID，得到摘要\n",
    "        summary = tokenizer.decode(\n",
    "            output_ids,\n",
    "            skip_special_tokens=True,\n",
    "            clean_up_tokenization_spaces=False\n",
    "        )\n",
    "    except:\n",
    "        # 如果出现异常，提示检查Transformers的版本号\n",
    "        return '请检查Transformers的版本号'\n",
    "    \n",
    "    return summary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from the default dictionary ...\n",
      "Loading model from cache C:\\Users\\28495\\AppData\\Local\\Temp\\jieba.cache\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------开始----------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading model cost 0.696 seconds.\n",
      "Prefix dict has been built successfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "迭代6次，收敛\n",
      "最大的3个值： [1.36031201 1.66904725 1.37443195]\n",
      "对应的索引： [5, 14, 20]\n",
      "结果：\n",
      "2024年前夕，李炮儿宣布要做一件大事，来为2023年顺利收尾，宣布要挑战一项吉尼斯世界纪录，经过团队的精心选题，最终宣布要挑战带领最多人跳“科目三”。\n",
      "最终，在大家的共同努力下，第二次挑战顺利完成，而吉尼斯认证官在统计线上、线下的舞者人数后，高兴地在台上宣布最终完成人数为357人，宣布李炮儿打破了一项新的吉尼斯世界纪录。\n",
      "那么按照李炮儿的这种挑战，下一次阿giao可以找些粉丝挑战最多人在一起“giao”的记录了，面筋哥可以组织一波最多人一起唱“烤面筋”的吉尼斯世界纪录。\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import tkinter as tk\n",
    "from tkinter import ttk, scrolledtext\n",
    "import jieba\n",
    "\n",
    "\n",
    "###################################################\n",
    "# UI界面实现\n",
    "###################################################\n",
    "\n",
    "def summarize_text():\n",
    "    input_text = input_text_widget.get(\"1.0\", \"end-1c\")\n",
    "    d = float(d_entry.get()) if d_entry.get() else 0.85\n",
    "    top = int(top_entry.get()) if top_entry.get() else 3\n",
    "    processing_method = processing_method_var.get()\n",
    "    use_stopwords = use_stopwords_var.get()\n",
    "    summary = summarize_text_rank(input_text, d=d, top=top, method=processing_method, use_stopwords=use_stopwords)\n",
    "    output_text_widget.delete(1.0, tk.END)\n",
    "    output_text_widget.insert(tk.END, summary)\n",
    "\n",
    "   \n",
    "def summarize_text_mt5():\n",
    "    input_text = input_text_widget.get(\"1.0\", \"end-1c\")\n",
    "    summary_result = summary_mt5(input_text)\n",
    "    output_text_widget_mt5.delete(1.0, tk.END)\n",
    "    output_text_widget_mt5.insert(tk.END, summary_result)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# 创建主窗口\n",
    "root = tk.Tk()\n",
    "root.title(\"中文文本自动摘要工具\")\n",
    "\n",
    "# 使用ttk模块中的样式调整\n",
    "style = ttk.Style()\n",
    "style.configure('TFrame', padding=10)\n",
    "style.configure('TButton', padding=(10, 5), font=('Helvetica', 10))\n",
    "style.configure('TLabel', font=('Helvetica', 10))\n",
    "\n",
    "# 创建输入文本框\n",
    "input_label_frame = ttk.LabelFrame(root, text=\"输入文本\")\n",
    "input_label_frame.grid(row=0, column=0, padx=10, pady=10, sticky=\"nsew\", columnspan=2)  # 设置columnspan为2，使其横跨两列\n",
    "input_text_widget = scrolledtext.ScrolledText(input_label_frame, wrap=tk.WORD, width=70, height=10)\n",
    "input_text_widget.pack(pady=10, fill='both', expand=True)\n",
    "\n",
    "# 创建摘要长度输入框，设置默认值为100\n",
    "frame1 = ttk.LabelFrame(root, text=\"TextRank参数设置\")\n",
    "frame1.grid(row=1, column=0, padx=10, pady=10, sticky=\"nsew\", columnspan=2)  # 设置columnspan为2，使其横跨两列\n",
    "\n",
    "# 创建停用词复选框\n",
    "use_stopwords_var = tk.BooleanVar(root)\n",
    "use_stopwords_var.set(True)  # 默认使用停用词\n",
    "use_stopwords_checkbutton = ttk.Checkbutton(frame1, text=\"使用停用词\", variable=use_stopwords_var)\n",
    "use_stopwords_checkbutton.grid(row=0, column=0, pady=5)\n",
    "\n",
    "\n",
    "default_d = 0.85\n",
    "d_label = ttk.Label(frame1, text=f\"阻尼系数:\")\n",
    "d_label.grid(row=1, column=0, padx=5, pady=5, sticky=\"w\")\n",
    "d_entry = ttk.Entry(frame1, width=10)\n",
    "d_entry.insert(0, str(default_d))\n",
    "d_entry.grid(row=1, column=1, padx=2, pady=5)\n",
    "\n",
    "\n",
    "default_top = 3\n",
    "top_label = ttk.Label(frame1, text=f\"摘要句数:\")\n",
    "top_label.grid(row=2, column=0, padx=5, pady=5, sticky=\"w\")\n",
    "top_entry = ttk.Entry(frame1, width=10)\n",
    "top_entry.insert(0, str(default_top))\n",
    "top_entry.grid(row=2, column=1, padx=2, pady=5)\n",
    "\n",
    "\n",
    "\n",
    "processing_method_var = tk.StringVar(root)\n",
    "processing_method_var.set(\"默认方式\")  # 设置默认选项\n",
    "processing_method_label = ttk.Label(frame1, text=\"相似度度量:\")\n",
    "processing_method_label.grid(row=3, column=0, padx=5, pady=5, sticky=\"w\")\n",
    "processing_method_menu = ttk.Combobox(frame1, textvariable=processing_method_var, values=[\"默认方式\", \"TF-IDF\"], width=10)\n",
    "processing_method_menu.grid(row=3, column=1, padx=2, pady=5)\n",
    "\n",
    "# 创建按钮，用于触发文本摘要\n",
    "summarize_button = ttk.Button(root, text=\"TextRank生成摘要\", command=summarize_text, style='TButton')\n",
    "summarize_button.grid(row=2, column=0, padx=(10, 5), pady=10)  # 添加横向和纵向的内边距\n",
    "\n",
    "summarize_button_mt5 = ttk.Button(root, text=\"MT5生成摘要\", command=summarize_text_mt5, style='TButton')\n",
    "summarize_button_mt5.grid(row=2, column=1, padx=(5, 10), pady=10)  # 添加横向和纵向的内边距\n",
    "\n",
    "\n",
    "# 创建输出文本框\n",
    "output_label_frame = ttk.LabelFrame(root, text=\"TextRank输出文本\")\n",
    "output_label_frame.grid(row=3, column=0, padx=10, pady=10, sticky=\"nsew\", columnspan=2)  # 设置columnspan为2，使其横跨两列\n",
    "output_text_widget = scrolledtext.ScrolledText(output_label_frame, wrap=tk.WORD, width=50, height=10)\n",
    "output_text_widget.pack(pady=10, fill='both', expand=True)\n",
    "\n",
    "output_label_frame_mt5 = ttk.LabelFrame(root, text=\"MT5输出文本\")\n",
    "output_label_frame_mt5.grid(row=4, column=0, padx=10, pady=10, sticky=\"nsew\", columnspan=2)  # 设置columnspan为2，使其横跨两列\n",
    "output_text_widget_mt5 = scrolledtext.ScrolledText(output_label_frame_mt5, wrap=tk.WORD, width=50, height=10)\n",
    "output_text_widget_mt5.pack(pady=10, fill='both', expand=True)\n",
    "\n",
    "# 设置行列权重，使得在窗口变大时，文本框和标签框都能够扩展\n",
    "for i in range(4):  # 设置所有行的权重为1\n",
    "    root.grid_rowconfigure(i, weight=1)\n",
    "root.grid_columnconfigure(0, weight=1)\n",
    "root.grid_columnconfigure(1, weight=1)\n",
    "\n",
    "# 运行主循环\n",
    "root.mainloop()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
