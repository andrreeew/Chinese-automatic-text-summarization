# 中文文本自动摘要

​		中文文本自动摘要生成，总共实现三种方式，第一种方式为TextRank，第二种方式为TextRank的变体，修改了相似度衡量方式，第三种方式为深度学习模型MT5生成。同时简单实现UI界面，方便使用。

​		TextRank的方法简单来说就是通过句子间的相似度关系实现对每个句子打分，分数最高的几个句子作为摘要。而mt5则是生成式seq2seq，可简单理解为通过前面的词预测后面的词。总体来看深度学习的mt5的效果会比TextRank好一些。

​		三种方式中，TextRank为无监督方法，不需要任何数据集训练即可使用。MT5模型使用了huggingface上面的开源模型[mT5_multilingual_XLSum](https://huggingface.co/csebuetnlp/mT5_multilingual_XLSum)，并使用了NLPCC2017的[task3](http://tcci.ccf.org.cn/conference/2017/taskdata.php)数据集进行微调。



## 效果

录了个简单视频用于展示，见[链接](https://www.bilibili.com/video/BV1ik4y1Q7pf/?vd_source=3bc6e7bf315dca64640ebe38352be259)

<div style="display: flex; justify-content: center;">
    <img src="https://github.com/andrreeew/Chinese-automatic-text-summarization/assets/113843225/2af33f89-cd9d-429d-9365-5c964a3e5e83" alt="image-20240112155323684" style="width: 300px;"/>
</div>






下面是一些样例结果。

#### 样例一：

7月11日，连续强降雨，让四川登上了中央气象台“头条”，涪江绵阳段水位迅速上涨，洪水一度漫过了宝成铁路涪江大桥桥墩基座，超过封锁水位。洪水在即，中国铁路成都局集团公司紧急调集两列重载货物列车，一前一后开上涪江大桥，每一列货车重量约四千吨，用“重车压梁”的方式，增强桥梁自重，抵御汹涌的洪水。从11日凌晨开始，四川境内成都、绵阳、广元等地连续强降雨，而四川北向出川大动脉—宝成铁路，便主要途径成绵广这一区域。连续的强降雨天气下，绵阳市境内的涪江水位迅速上涨，一度危及到了宝成铁路涪江大桥的安全，上午10时，水位已经超过了涪江大桥上、下行大桥的封锁水位。记者从中国铁路成都局集团公司绵阳工务段了解到，上行线涪江大桥，全长393米，建成于1953年；下行线涪江大桥，全长438米，建成于1995年。“涪江大桥上游有一个水电站，由于洪水太大，水电站已无法发挥调节水位的作用。”情况紧急，铁路部门决定采用“重车压梁”的方式，增强桥梁自重，提高洪峰对桥墩冲刷时的梁体稳定性。简单来说，就是将重量大的货物列车开上涪江大桥，用货车的自重，帮助桥梁抵御汹涌的洪水。恰好，绵阳工务段近期正在进行线路大修，铁路专用的卸砟车，正好停放在绵阳附近。迎着汹涌的洪水，两列重载货车驶向宝成铁路涪江大桥。上午10时30分，第一列46052次货车，从绵阳北站开出进入上行涪江桥。上午11时15分，第二列22001次货车，从皂角铺站进入下行涪江桥。这是两列超过45节编组的重载货物列车，业内称铁路专用卸砟车，俗称“老K车”，车厢里装载的均为铁路道砟，每辆车的砟石的重量在70吨左右。记者从绵阳工务段了解到，货车里满载的砟石、加上一列货车的自重，两列“压桥”的货运列车，每一列的重量超过四千吨。“采用重车压梁的方式来应对水害，在平时的抢险中很少用到。”据了解，在绵阳工务段，上一次采用重车压梁，至少已经是二十年前的事。下午4时许，经铁路部门观测，洪峰过后，涪江水位开始下降，目前已经低于桥梁封锁水位。从下午4点37分开始，两列火车开始撤离涪江大桥。在桥上停留约6个小时后，两列重载货物列车成功完成了“保桥任务”，宝成铁路涪江大桥平安了！



TextRank:

洪水在即，中国铁路成都局集团公司紧急调集两列重载货物列车，一前一后开上涪江大桥，每一列货车重量约四千吨，用“重车压梁”的方式，增强桥梁自重，抵御汹涌的洪水。
连续的强降雨天气下，绵阳市境内的涪江水位迅速上涨，一度危及到了宝成铁路涪江大桥的安全，上午10时，水位已经超过了涪江大桥上、下行大桥的封锁水位。
简单来说，就是将重量大的货物列车开上涪江大桥，用货车的自重，帮助桥梁抵御汹涌的洪水。



TextRank+TF-IDF:

7月11日，连续强降雨，让四川登上了中央气象台“头条”，涪江绵阳段水位迅速上涨，洪水一度漫过了宝成铁路涪江大桥桥墩基座，超过封锁水位。
洪水在即，中国铁路成都局集团公司紧急调集两列重载货物列车，一前一后开上涪江大桥，每一列货车重量约四千吨，用“重车压梁”的方式，增强桥梁自重，抵御汹涌的洪水。
简单来说，就是将重量大的货物列车开上涪江大桥，用货车的自重，帮助桥梁抵御汹涌的洪水。



mt5:

7月11日,连续强降雨,让四川登上了中央气象台“头条”。四川北向出川大动脉—宝成铁路,也主要途径成绵广。



#### 样例二：

网红李炮儿是一位拥有千万粉丝的网红，喜欢拍摄一些挑战类视频，在这些挑战中，李炮儿凭借着创意的选题，幽默的风格，被大家喜欢。比如挑战过体验印度式洗脸、跑马拉松、当一天特警、cos瑶参加漫展、扮演蜘蛛侠进幼儿园，既搞笑又特别。而要说最让大家喜欢两次挑战，一次是去挑战参加《中国好声音》，网友们本以为是炮灰，哪成想他如此有实力，挺进了决赛，还险些出道。而另一次则是，李炮儿应粉丝要求，去看周杰伦演唱会并且和周杰伦合唱，李炮儿在演唱会上为了吸引周杰伦的注意也是花费了不少心思，终于获得周杰伦的注意，并成功获得了合唱的机会。而近日，李炮儿再次完成了一项挑战，带300多位舞者齐跳科目三，打破了世界纪录，但没想到却遭到全网嘲讽。2024年前夕，李炮儿宣布要做一件大事 ，来为2023年顺利收尾，宣布要挑战一项吉尼斯世界纪录，经过团队的精心选题，最终宣布要挑战带领最多人跳“科目三”。于是，李炮儿联系了吉尼斯认证官，并火速组织了一个几百人的团队（包括线下、线上），租了一个场地加紧训练，还请了专业的舞蹈老师指导。经过了大概一天的训练，李炮儿带领百人团队在辽宁沈阳步行街开始了挑战，百人的团队小伙伴们分成了横竖数排，以此排开。李炮儿则站在最前端领队。当晚正值跨年夜，街上的人十分多，纷纷站在两侧观看。而随着吉尼斯认证官吴晓红，在查验好人数和队形，在台上宣布“世界上最多人跳科目三”项目挑战开始后，音乐响起，数百人团队开始一起随音乐扭动，场面十分之“壮观”，而于此同时，线上还有200多人同时视频连线挑战。不过，在 第一次挑战过程中，线上的网络出了一些问题，导致线上的小伙伴出现了掉线、卡顿等状况，所以，第一次挑战失败。于是在重新检查网络后，开始了第二次挑战。而在第二次挑战前，李炮儿也是为现场和线上的小伙伴们打气，鼓励大家加油，一定要挑战成功。最终，在大家的共同努力下，第二次挑战顺利完成，而吉尼斯认证官在统计线上、线下的舞者人数后，高兴地在台上宣布最终完成人数为357人，宣布李炮儿打破了一项 新的吉尼斯世界纪录。而李炮儿也上台领取了吉尼斯认证奖牌，和小伙伴来了一张大合影，还上台表达了得奖的感言，并为家乡宣传，希望大家来沈阳游玩。不过，李炮儿在发布视频后，没有像以往一样迎来大家的夸赞，而是引来一片嘲讽声音。翻看网友们的嘲讽原因，大致有以下三个方面：第一， 感觉这次挑战的内容没啥难度，也没有什么特点，只要人足够多，就肯定能挑战成功。而且挑战成功的条件十分地简单，只要所有的参与者知道动作，跳够两分钟就算成功。简直就是小朋友过家家。那么按照李炮儿的这种挑战，下一次阿giao可以找些粉丝挑战最多人在一起“giao”的记录了，面筋哥可以组织一波最多人一起唱“烤面筋”的吉尼斯世界纪录。第二， 网友们也感觉“吉尼斯”个项目越来越尴尬，不少网友直言，以前感觉吉尼斯纪录都是好厉害的样子，而现在感觉吉尼斯记录就是个笑话。实际上，吉尼斯世界纪录并非所有的记录都十分有难度，而且很多记录都十分奇葩，比如有用屁股坐核桃、大腿夹西瓜、甚至各种因为太无聊，没有人继续挑战的，在这些记录中，以堆人数而挑战成功的也有很多。比如四川曾有2.2万大妈一起跳广场舞打破吉尼斯世界纪录。只不过，李炮儿前期的视频要么给大家带来快乐，要么是实打实的有实力，而这次虽然花费了很大的力气，也找了很多人，但确实是毫无挑战性，和大家的预期相差甚远。当然，李炮儿利用这次活动，为家乡宣传，初心还是十分好的。



TextRank:

2024年前夕，李炮儿宣布要做一件大事，来为2023年顺利收尾，宣布要挑战一项吉尼斯世界纪录，经过团队的精心选题，最终宣布要挑战带领最多人跳“科目三”。
最终，在大家的共同努力下，第二次挑战顺利完成，而吉尼斯认证官在统计线上、线下的舞者人数后，高兴地在台上宣布最终完成人数为357人，宣布李炮儿打破了一项新的吉尼斯世界纪录。
那么按照李炮儿的这种挑战，下一次阿giao可以找些粉丝挑战最多人在一起“giao”的记录了，面筋哥可以组织一波最多人一起唱“烤面筋”的吉尼斯世界纪录。



TextRank+TF-IDF:

而在第二次挑战前，李炮儿也是为现场和线上的小伙伴们打气，鼓励大家加油，一定要挑战成功。
最终，在大家的共同努力下，第二次挑战顺利完成，而吉尼斯认证官在统计线上、线下的舞者人数后，高兴地在台上宣布最终完成人数为357人，宣布李炮儿打破了一项新的吉尼斯世界纪录。
那么按照李炮儿的这种挑战，下一次阿giao可以找些粉丝挑战最多人在一起“giao”的记录了，面筋哥可以组织一波最多人一起唱“烤面筋”的吉尼斯世界纪录。



mt5:

近日,网红李炮儿再次完成一项挑战,带300多位舞者齐跳科目三,打破了世界纪录,但没想到却遭到全网嘲讽。





## 如何使用

首先导入所需库，所需的依赖如下

```
python = 3.7.1
jieba = 0.42.1
numpy = 1.21.5
scikit-learn = 1.0.2
transformers = 4.11.0
jupyter = 1.0.0
pytorch = 1.7.0
```

如安装pytorch有疑问，可参考[链接](https://pytorch.org/get-started/previous-versions/)。

接着直接跑main.ipynb文件即可，UI界面即可出现。

注意由于mt5模型数据太大，故在这里移除，但是不影响TextRank方法的使用。我将mt5模型数据放在[百度网盘](https://pan.baidu.com/s/1eU3JPLGi8mP2oKnRmNEQXQ)，提取码为**jynk**。如果您想体验mt5，从网盘下载mt5-base文件夹，将mt5-base文件夹放在与main.ipynb同级的目录下，再重新运行main.ipynb文件即可。并且注意mt5生成速度较慢，生成时请耐心等待。





## 方法

### TextRank

简单来讲通过句子间的相似度关系实现对每个句子打分，分数最高的几个句子作为摘要。具体来说，依据文本构造一个无向图 $G$ ，文本里的每个句子当作图 $G$ 的一个节点 $N$ ，每两个节点之间用一条边相连，边的权重代表两个节点的相似度，也就是两个句子的相似度。我们记节点 $N_i$ 和节点 $N_j$ 之间的边权重为 $w_{ij}$，节点 $V_i$ 的分数为 $WS(N_i)$ 。初始情况下每个节点的分数为1。后每次用如下公式更新全部节点，收敛。
$$WS(N_i) = (1 - d) + d \times \sum_{j } \frac{w_{ji}}{\sum_{k }w_{jk}} \times WS(N_j)$$
其中 $d$ 为阻尼系数，一般设置为0.85。在这里面最主要的就是节点 $N_i$ 和节点 $N_j$ 之间的边权重为 $w_{ij}$ ，也就是句子之间的相似度如何定义。

这个是比较灵活的，我们可以使用不同方法来定义文本相似度。

#### 相似度衡量

##### 原方法

按照[TextRank原论文](https://aclanthology.org/W04-3252.pdf)中的方法，我们两个句子 $S_i$ 和 $S_j$ 看作两个集合，集合中的元素是句子里面的词，则两个句子相似度 $Sim(S_i,S_j)$ 定义为:
$$Sim(S_i, S_j) =\frac{|\{w_k|w_k\in S_i\\& w_k\in S_j\}|}{log(|S_i|)+log(|S_j|)}$$
也就是认为两个句子中同样的词出现得越多，两个句子越相似。



##### TF-IDF

当然这个相似度可以不按照原文中的来做，我们这里还做了另一种相似度衡量。也就是比较经典的TF-IDF。简单来说就是我们将每个句子编码成向量，然后使用向量之间的余弦值来衡量相似度。具体而言我们将文档中的所有词看作一个词库，假设有$N$个词，对于每个句子计算每个词对应的TF-IDF值，最终每个句子被编码为长度为$N$的向量，再通过向量之间的余弦值来衡量相似度。



### MT5

T5 是 Google 出品的预训练模型，架构为Transformers，训练方式也就是常用的无监督预训练+有监督微调。具体而言没太多可讲的，就是大数据训练，网络具体细节见论文[Exploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer](https://research.google/pubs/exploring-the-limits-of-transfer-learning-with-a-unified-text-to-text-transformer/)。



## 讨论

TextRank尽管为很早的作品，但是我们就可以看到GCN的影子。

TextRank为什么会有些效果，这是比较有趣的。可以认为主要在于它综合考虑了文本单元（顶点）的局部上下文以及从整个文本（图）递归提取的信息。通过在文本上构建图，TextRank能够识别文本中不同句子的联系，并实现“推荐”。一个句子会“推荐”其他与他相关的句子，而推荐的强度是通过递归计算提出推荐的句子的重要性得到的。对于高度被其他句子推荐的句子来说，在给定文本中可能提供更多信息，因此它们会获得更高的分数。

不过总体来说，TextRank方法存在一些不足之处。首先，它通过从文档中选择句子作为摘要，但某些文档可能缺乏合适的主旨句，从而难以概括整个文档的核心内容。其次，所采用的相似度衡量方式存在问题，因为它将每个词视为彼此无关，而实际上词与词之间可能存在相似性。对于近义词而言，这种方法无法捕捉它们之间的关联；同时，对于指代词，该方法也无法识别指代关系。当然，通过采用一些基于word2vec等方法，可能更有效地实现对词汇之间相似性的准确衡量。
